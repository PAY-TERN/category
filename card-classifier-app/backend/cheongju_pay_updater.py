#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì²­ì£¼í˜ì´ ì¹´í…Œê³ ë¦¬ ì—…ë°ì´íŠ¸ ìŠ¤í¬ë¦½íŠ¸
- ì¹´ë“œ ë¶„ë¥˜ ê²°ê³¼ CSVì™€ ì²­ì£¼ì‚¬ë‘ ìƒí’ˆê¶Œ ê°€ë§¹ì  CSVë¥¼ ë¹„êµ
- ê²¹ì¹˜ëŠ” ê°€ë§¹ì ì˜ ì¹´í…Œê³ ë¦¬ë¥¼ "ì²­ì£¼í˜ì´"ë¡œ ë³€ê²½
"""

import pandas as pd
import numpy as np
import re
from pathlib import Path
import logging
from datetime import datetime
from typing import List, Set, Dict, Tuple

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(levelname)s:%(name)s:%(message)s'
)
logger = logging.getLogger(__name__)

class CheongJuPayUpdater:
    """ì²­ì£¼í˜ì´ ì¹´í…Œê³ ë¦¬ ì—…ë°ì´íŠ¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.classification_df = None
        self.cheongju_merchants_df = None
        self.matched_merchants = set()
        self.updated_count = 0
        

    def load_classification_results(self, file_path: str, merchant_column: str = 'ê°€ë§¹ì ëª…') -> pd.DataFrame:
        """ì¹´ë“œ ë¶„ë¥˜ ê²°ê³¼ CSV íŒŒì¼ ë¡œë“œ"""
        logger.info(f"ğŸ“ ì¹´ë“œ ë¶„ë¥˜ ê²°ê³¼ ë¡œë“œ: {file_path}")
        
        try:
            if file_path.endswith('.xlsx') or file_path.endswith('.xls'):
                df = pd.read_excel(file_path)
            else:
                # CSV íŒŒì¼ ì¸ì½”ë”© ìë™ ê°ì§€
                try:
                    df = pd.read_csv(file_path, encoding='utf-8')
                except UnicodeDecodeError:
                    try:
                        df = pd.read_csv(file_path, encoding='cp949')
                    except UnicodeDecodeError:
                        df = pd.read_csv(file_path, encoding='euc-kr')
            
            logger.info(f"ğŸ“Š ë¡œë“œëœ ë°ì´í„°: {len(df)}ê°œ í–‰, {len(df.columns)}ê°œ ì»¬ëŸ¼")
            logger.info(f"ì»¬ëŸ¼ëª…: {list(df.columns)}")
            
            # ê°€ë§¹ì  ì»¬ëŸ¼ í™•ì¸
            if merchant_column not in df.columns:
                # ê°€ë§¹ì  ì»¬ëŸ¼ ìë™ ê°ì§€
                possible_columns = ['ê°€ë§¹ì ëª…', 'ê°€ë§¹ì ', 'merchant', 'store', 'ìƒì ëª…', 'ì—…ì²´ëª…']
                found_column = None
                
                for col in df.columns:
                    for possible in possible_columns:
                        if possible in col:
                            found_column = col
                            break
                    if found_column:
                        break
                
                if found_column:
                    logger.info(f"ğŸ” ê°€ë§¹ì  ì»¬ëŸ¼ ìë™ ê°ì§€: {found_column}")
                    merchant_column = found_column
                else:
                    raise ValueError(f"ê°€ë§¹ì  ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(df.columns)}")
            
            # ì¹´í…Œê³ ë¦¬ ì»¬ëŸ¼ í™•ì¸
            if 'ì¹´í…Œê³ ë¦¬' not in df.columns:
                # ì¹´í…Œê³ ë¦¬ ì»¬ëŸ¼ ìƒì„±
                df['ì¹´í…Œê³ ë¦¬'] = 'ê¸°íƒ€'
                logger.info("âš ï¸ ì¹´í…Œê³ ë¦¬ ì»¬ëŸ¼ì´ ì—†ì–´ì„œ 'ê¸°íƒ€'ë¡œ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤.")
            
            self.classification_df = df
            self.merchant_column = merchant_column
            
            # ê°€ë§¹ì ëª… ë¶„í¬ í™•ì¸
            unique_merchants = df[merchant_column].nunique()
            logger.info(f"ğŸ“Š ê³ ìœ  ê°€ë§¹ì  ìˆ˜: {unique_merchants}ê°œ")
            
            # ê¸°ì¡´ ì¹´í…Œê³ ë¦¬ ë¶„í¬
            if 'ì¹´í…Œê³ ë¦¬' in df.columns:
                category_dist = df['ì¹´í…Œê³ ë¦¬'].value_counts()
                logger.info(f"ğŸ“Š ê¸°ì¡´ ì¹´í…Œê³ ë¦¬ ë¶„í¬:")
                for category, count in category_dist.head(10).items():
                    logger.info(f"   - {category}: {count}ê°œ")
            
            return df
            
        except Exception as e:
            logger.error(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise e
    
    def load_cheongju_merchants(self, file_path: str, merchant_column: str = None) -> pd.DataFrame:
        """ì²­ì£¼ì‚¬ë‘ ìƒí’ˆê¶Œ ê°€ë§¹ì  CSV íŒŒì¼ ë¡œë“œ"""
        logger.info(f"ğŸ“ ì²­ì£¼ì‚¬ë‘ ìƒí’ˆê¶Œ ê°€ë§¹ì  ë¡œë“œ: {file_path}")
        
        try:
            if file_path.endswith('.xlsx') or file_path.endswith('.xls'):
                df = pd.read_excel(file_path)
            else:
                # CSV íŒŒì¼ ì¸ì½”ë”© ìë™ ê°ì§€
                try:
                    df = pd.read_csv(file_path, encoding='utf-8')
                except UnicodeDecodeError:
                    try:
                        df = pd.read_csv(file_path, encoding='cp949')
                    except UnicodeDecodeError:
                        df = pd.read_csv(file_path, encoding='euc-kr')
            
            logger.info(f"ğŸ“Š ë¡œë“œëœ ì²­ì£¼ ê°€ë§¹ì : {len(df)}ê°œ í–‰, {len(df.columns)}ê°œ ì»¬ëŸ¼")
            logger.info(f"ì»¬ëŸ¼ëª…: {list(df.columns)}")
            
            # ê°€ë§¹ì  ì»¬ëŸ¼ ìë™ ê°ì§€
            if merchant_column is None:
                possible_columns = ['ê°€ë§¹ì ëª…', 'ê°€ë§¹ì ', 'merchant', 'store', 'ìƒì ëª…', 'ì—…ì²´ëª…', 'ìƒí˜¸ëª…', 'ì—…ì†Œëª…']
                found_column = None
                
                for col in df.columns:
                    for possible in possible_columns:
                        if possible in col:
                            found_column = col
                            break
                    if found_column:
                        break
                
                if found_column:
                    merchant_column = found_column
                    logger.info(f"ğŸ” ì²­ì£¼ ê°€ë§¹ì  ì»¬ëŸ¼ ìë™ ê°ì§€: {found_column}")
                else:
                    # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì„ ê°€ë§¹ì ëª…ìœ¼ë¡œ ì‚¬ìš©
                    merchant_column = df.columns[0]
                    logger.warning(f"âš ï¸ ê°€ë§¹ì  ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í•´ ì²« ë²ˆì§¸ ì»¬ëŸ¼ ì‚¬ìš©: {merchant_column}")
            
            self.cheongju_merchants_df = df
            self.cheongju_merchant_column = merchant_column
            
            # ê³ ìœ  ê°€ë§¹ì  ìˆ˜ í™•ì¸
            unique_cheongju = df[merchant_column].nunique()
            logger.info(f"ğŸ“Š ì²­ì£¼ ê³ ìœ  ê°€ë§¹ì  ìˆ˜: {unique_cheongju}ê°œ")
            
            # ìƒ˜í”Œ ë°ì´í„° ì¶œë ¥
            logger.info(f"ğŸ“‹ ì²­ì£¼ ê°€ë§¹ì  ìƒ˜í”Œ:")
            for i, merchant in enumerate(df[merchant_column].head(5)):
                logger.info(f"   {i+1}. {merchant}")
            
            return df
            
        except Exception as e:
            logger.error(f"âŒ ì²­ì£¼ ê°€ë§¹ì  íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise e
    
    def normalize_merchant_name(self, name: str) -> str:
        """ì§€ì ë³„ ê³ ìœ ì„±ì„ ìœ ì§€í•˜ëŠ” ì •ê·œí™”"""
        if pd.isna(name):
            return ""
        
        name = str(name).strip()
        name = re.sub(r'\s+', ' ', name)  # ê³µë°± ì •ê·œí™”
        name = name.lower()
        
        # âŒ ê¸°ì¡´: ëª¨ë“  ì ‘ë¯¸ì‚¬ ì œê±°
        # âœ… ê°œì„ : ì§€ì  ì •ë³´ëŠ” ë³´ì¡´í•˜ê³  ì¼ë°˜ ì ‘ë¯¸ì‚¬ë§Œ ì œê±°
        general_suffixes = ['(ì£¼)', 'ãˆœ', 'ì„œë¹„ìŠ¤']  # ì§€ì ëª…ì´ ì•„ë‹Œ ê²ƒë“¤ë§Œ
        for suffix in general_suffixes:
            if name.endswith(suffix):
                name = name[:-len(suffix)].strip()
        
        return name
    
    def find_matching_merchants(self, exact_match: bool = True, fuzzy_match: bool = True) -> Set[str]:
        """ë§¤ì¹­ë˜ëŠ” ê°€ë§¹ì  ì°¾ê¸°"""
        logger.info("ğŸ” ê°€ë§¹ì  ë§¤ì¹­ ì‹œì‘...")
        
        if self.classification_df is None or self.cheongju_merchants_df is None:
            raise ValueError("ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ë¶„ë¥˜ ê²°ê³¼ì˜ ê°€ë§¹ì ëª…ë“¤
        classification_merchants = set(self.classification_df[self.merchant_column].dropna().astype(str))
        
        # ì²­ì£¼ ê°€ë§¹ì ëª…ë“¤
        cheongju_merchants = set(self.cheongju_merchants_df[self.cheongju_merchant_column].dropna().astype(str))
        
        matched = set()
        
        # 1ë‹¨ê³„: ì •í™•í•œ ë§¤ì¹­
        if exact_match:
            exact_matches = classification_merchants.intersection(cheongju_merchants)
            matched.update(exact_matches)
            logger.info(f"âœ… ì •í™•í•œ ë§¤ì¹­: {len(exact_matches)}ê°œ")
            
            if len(exact_matches) > 0:
                logger.info("ğŸ“‹ ì •í™•í•œ ë§¤ì¹­ ìƒ˜í”Œ:")
                for i, merchant in enumerate(list(exact_matches)[:5]):
                    logger.info(f"   {i+1}. {merchant}")
        
        # 2ë‹¨ê³„: ì •ê·œí™”ëœ ë§¤ì¹­
        if fuzzy_match:
            logger.info("ğŸ”„ ì •ê·œí™”ëœ ë§¤ì¹­ ì‹œë„...")
            
            # ì •ê·œí™”ëœ ê°€ë§¹ì ëª… ë”•ì…”ë„ˆë¦¬ ìƒì„±
            normalized_classification = {
                self.normalize_merchant_name(m): m 
                for m in classification_merchants
            }
            
            normalized_cheongju = {
                self.normalize_merchant_name(m): m 
                for m in cheongju_merchants
            }
            
            # ì •ê·œí™”ëœ ì´ë¦„ìœ¼ë¡œ ë§¤ì¹­
            normalized_matches = set(normalized_classification.keys()).intersection(
                set(normalized_cheongju.keys())
            )
            
            # ì›ë³¸ ì´ë¦„ìœ¼ë¡œ ë³€í™˜
            fuzzy_matches = set()
            for norm_name in normalized_matches:
                if norm_name in normalized_classification:
                    original_name = normalized_classification[norm_name]
                    if original_name not in matched:  # ì¤‘ë³µ ì œê±°
                        fuzzy_matches.add(original_name)
            
            matched.update(fuzzy_matches)
            logger.info(f"âœ… ì •ê·œí™” ë§¤ì¹­: {len(fuzzy_matches)}ê°œ (ì¤‘ë³µ ì œì™¸)")
            
            if len(fuzzy_matches) > 0:
                logger.info("ğŸ“‹ ì •ê·œí™” ë§¤ì¹­ ìƒ˜í”Œ:")
                for i, merchant in enumerate(list(fuzzy_matches)[:5]):
                    normalized = self.normalize_merchant_name(merchant)
                    logger.info(f"   {i+1}. {merchant} -> {normalized}")
        
        # 3ë‹¨ê³„: ë¶€ë¶„ ë¬¸ìì—´ ë§¤ì¹­ (ì„ íƒì )
        partial_matches = set()
        if len(matched) < 10:  # ë§¤ì¹­ì´ ì ì„ ë•Œë§Œ ì‹¤í–‰
            logger.info("ğŸ”„ ë¶€ë¶„ ë¬¸ìì—´ ë§¤ì¹­ ì‹œë„...")
            
            for c_merchant in classification_merchants:
                if c_merchant in matched:
                    continue
                    
                c_normalized = self.normalize_merchant_name(c_merchant)
                if len(c_normalized) < 3:  # ë„ˆë¬´ ì§§ì€ ì´ë¦„ì€ ì œì™¸
                    continue
                
                for j_merchant in cheongju_merchants:
                    j_normalized = self.normalize_merchant_name(j_merchant)
                    
                    # ë¶€ë¶„ ë¬¸ìì—´ í™•ì¸ (ì–‘ë°©í–¥)
                    if (len(c_normalized) >= 3 and c_normalized in j_normalized) or \
                       (len(j_normalized) >= 3 and j_normalized in c_normalized):
                        partial_matches.add(c_merchant)
                        logger.debug(f"ë¶€ë¶„ ë§¤ì¹­: {c_merchant} <-> {j_merchant}")
                        break
            
            matched.update(partial_matches)
            logger.info(f"âœ… ë¶€ë¶„ ë§¤ì¹­: {len(partial_matches)}ê°œ")
        
        self.matched_merchants = matched
        logger.info(f"ğŸ¯ ì´ ë§¤ì¹­ëœ ê°€ë§¹ì : {len(matched)}ê°œ")
        
        return matched
    
    def update_categories_to_cheongju_pay(self) -> int:
        """ë§¤ì¹­ëœ ê°€ë§¹ì ë“¤ì˜ ì¹´í…Œê³ ë¦¬ë¥¼ "ì²­ì£¼í˜ì´"ë¡œ ì—…ë°ì´íŠ¸"""
        logger.info("ğŸ”„ ì¹´í…Œê³ ë¦¬ë¥¼ 'ì²­ì£¼í˜ì´'ë¡œ ì—…ë°ì´íŠ¸ ì¤‘...")
        
        if len(self.matched_merchants) == 0:
            logger.warning("âš ï¸ ë§¤ì¹­ëœ ê°€ë§¹ì ì´ ì—†ìŠµë‹ˆë‹¤.")
            return 0
        
        # ì¹´í…Œê³ ë¦¬ ì—…ë°ì´íŠ¸
        updated_count = 0
        update_log = []
        
        for merchant in self.matched_merchants:
            # í•´ë‹¹ ê°€ë§¹ì ì˜ ëª¨ë“  í–‰ì„ ì—…ë°ì´íŠ¸
            mask = self.classification_df[self.merchant_column] == merchant
            affected_rows = mask.sum()
            
            if affected_rows > 0:
                # ê¸°ì¡´ ì¹´í…Œê³ ë¦¬ ì €ì¥ (ë¡œê·¸ìš©)
                old_categories = self.classification_df.loc[mask, 'ì¹´í…Œê³ ë¦¬'].unique()
                
                # ì¹´í…Œê³ ë¦¬ ì—…ë°ì´íŠ¸
                self.classification_df.loc[mask, 'ì¹´í…Œê³ ë¦¬'] = 'ì²­ì£¼í˜ì´'
                
                updated_count += affected_rows
                update_log.append({
                    'merchant': merchant,
                    'rows_affected': affected_rows,
                    'old_categories': list(old_categories)
                })
        
        self.updated_count = updated_count
        
        logger.info(f"âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ: {updated_count}ê°œ í–‰")
        logger.info(f"ğŸ“Š ì—…ë°ì´íŠ¸ëœ ê°€ë§¹ì : {len(self.matched_merchants)}ê°œ")
        
        # ì—…ë°ì´íŠ¸ ë¡œê·¸ ì¶œë ¥
        logger.info("ğŸ“‹ ì—…ë°ì´íŠ¸ ìƒì„¸ ë‚´ì—­:")
        for i, log in enumerate(update_log[:10]):  # ìƒìœ„ 10ê°œë§Œ ì¶œë ¥
            merchant = log['merchant']
            rows = log['rows_affected']
            old_cats = ', '.join(log['old_categories'])
            logger.info(f"   {i+1}. {merchant}: {rows}ê°œ í–‰ ({old_cats} -> ì²­ì£¼í˜ì´)")
        
        if len(update_log) > 10:
            logger.info(f"   ... ì™¸ {len(update_log) - 10}ê°œ ê°€ë§¹ì ")
        
        return updated_count
    
    def save_updated_results(self, output_path: str = None) -> str:
        """ì—…ë°ì´íŠ¸ëœ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        if output_path is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = f"card_classification_with_cheongju_pay_{timestamp}.xlsx"
        
        logger.info(f"ğŸ’¾ ì—…ë°ì´íŠ¸ëœ ê²°ê³¼ ì €ì¥: {output_path}")
        
        try:
            # ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥
            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
                # ë©”ì¸ ê²°ê³¼
                self.classification_df.to_excel(writer, sheet_name='Classification_Results', index=False)
                
                # ë§¤ì¹­ëœ ê°€ë§¹ì  ëª©ë¡
                if len(self.matched_merchants) > 0:
                    matched_df = pd.DataFrame({
                        'ë§¤ì¹­ëœ_ê°€ë§¹ì ': list(self.matched_merchants),
                        'ì¹´í…Œê³ ë¦¬': 'ì²­ì£¼í˜ì´'
                    })
                    matched_df.to_excel(writer, sheet_name='Matched_Merchants', index=False)
                
                # í†µê³„ ì •ë³´
                stats_df = pd.DataFrame({
                    'í•­ëª©': [
                        'ì „ì²´ ê±°ë˜ ê±´ìˆ˜',
                        'ê³ ìœ  ê°€ë§¹ì  ìˆ˜',
                        'ë§¤ì¹­ëœ ê°€ë§¹ì  ìˆ˜',
                        'ì²­ì£¼í˜ì´ë¡œ ë³€ê²½ëœ ê±°ë˜ ê±´ìˆ˜',
                        'ì²­ì£¼í˜ì´ ë¹„ìœ¨(%)'
                    ],
                    'ê°’': [
                        len(self.classification_df),
                        self.classification_df[self.merchant_column].nunique(),
                        len(self.matched_merchants),
                        self.updated_count,
                        round(self.updated_count / len(self.classification_df) * 100, 2)
                    ]
                })
                stats_df.to_excel(writer, sheet_name='Statistics', index=False)
            
            logger.info(f"âœ… ì €ì¥ ì™„ë£Œ: {output_path}")
            
            # ìµœì¢… ì¹´í…Œê³ ë¦¬ ë¶„í¬ ì¶œë ¥
            final_dist = self.classification_df['ì¹´í…Œê³ ë¦¬'].value_counts()
            logger.info(f"ğŸ“Š ìµœì¢… ì¹´í…Œê³ ë¦¬ ë¶„í¬:")
            for category, count in final_dist.items():
                percentage = count / len(self.classification_df) * 100
                logger.info(f"   - {category}: {count}ê°œ ({percentage:.1f}%)")
            
            return output_path
            
        except Exception as e:
            logger.error(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")
            raise e
    
    def generate_summary_report(self) -> Dict:
        """ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±"""
        if self.classification_df is None:
            return {}
        
        total_transactions = len(self.classification_df)
        unique_merchants = self.classification_df[self.merchant_column].nunique()
        
        # ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬
        category_dist = self.classification_df['ì¹´í…Œê³ ë¦¬'].value_counts().to_dict()
        
        # ì²­ì£¼í˜ì´ ê´€ë ¨ í†µê³„
        cheongju_pay_count = category_dist.get('ì²­ì£¼í˜ì´', 0)
        cheongju_pay_ratio = (cheongju_pay_count / total_transactions * 100) if total_transactions > 0 else 0
        
        summary = {
            'total_transactions': total_transactions,
            'unique_merchants': unique_merchants,
            'matched_merchants_count': len(self.matched_merchants),
            'updated_transactions': self.updated_count,
            'cheongju_pay_transactions': cheongju_pay_count,
            'cheongju_pay_ratio': round(cheongju_pay_ratio, 2),
            'category_distribution': category_dist,
            'matched_merchants': list(self.matched_merchants)
        }
        
        return summary

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸª ì²­ì£¼í˜ì´ ì¹´í…Œê³ ë¦¬ ì—…ë°ì´íŠ¸ ìŠ¤í¬ë¦½íŠ¸")
    print("=" * 50)
    
    updater = CheongJuPayUpdater()
    
    # 1. ì¹´ë“œ ë¶„ë¥˜ ê²°ê³¼ íŒŒì¼ ë¡œë“œ (ê³ ì • ê²½ë¡œ)
    classification_file = "card.xlsx"
    merchant_column = 'ê°€ë§¹ì ëª…'
    
    print(f"ğŸ“ ì¹´ë“œ ë¶„ë¥˜ ê²°ê³¼ íŒŒì¼: {classification_file}")
    
    try:
        updater.load_classification_results(classification_file, merchant_column)
    except Exception as e:
        print(f"âŒ ì¹´ë“œ ë¶„ë¥˜ ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        print("ğŸ’¡ 'card.xlsx' íŒŒì¼ì´ í˜„ì¬ ë””ë ‰í† ë¦¬ì— ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    
    # 2. ì²­ì£¼ì‚¬ë‘ ìƒí’ˆê¶Œ ê°€ë§¹ì  íŒŒì¼ ë¡œë“œ (ê³ ì • ê²½ë¡œ)
    cheongju_file = "cheongju-pay_u.csv"
    
    print(f"ğŸ“ ì²­ì£¼ì‚¬ë‘ ìƒí’ˆê¶Œ ê°€ë§¹ì  íŒŒì¼: {cheongju_file}")
    
    try:
        updater.load_cheongju_merchants(cheongju_file)
    except Exception as e:
        print(f"âŒ ì²­ì£¼ ê°€ë§¹ì  íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        print("ğŸ’¡ 'cheongju-pay_u.csv' íŒŒì¼ì´ í˜„ì¬ ë””ë ‰í† ë¦¬ì— ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    
    # 3. ìë™ìœ¼ë¡œ ê¶Œì¥ ë§¤ì¹­ ë°©ì‹ ì‚¬ìš© (ì •í™•í•œ + ì •ê·œí™” ë§¤ì¹­)
    print("\nğŸ” ë§¤ì¹­ ë°©ì‹: ì •í™•í•œ ë§¤ì¹­ + ì •ê·œí™” ë§¤ì¹­ (ìë™ ì„ íƒ)")
    
    exact_match = True
    fuzzy_match = True
    
    # 4. ë§¤ì¹­ ì‹¤í–‰
    try:
        matched_merchants = updater.find_matching_merchants(
            exact_match=exact_match, 
            fuzzy_match=fuzzy_match
        )
        
        if len(matched_merchants) == 0:
            print("âš ï¸ ë§¤ì¹­ëœ ê°€ë§¹ì ì´ ì—†ìŠµë‹ˆë‹¤.")
            print("ğŸ’¡ ë‹¤ë¥¸ ë§¤ì¹­ ë°©ì‹ì„ ì‹œë„í•˜ê±°ë‚˜ íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return
        
        # 5. ë§¤ì¹­ ê²°ê³¼ í™•ì¸
        print(f"\nğŸ¯ ë§¤ì¹­ëœ ê°€ë§¹ì : {len(matched_merchants)}ê°œ")
        print("ğŸ“‹ ë§¤ì¹­ëœ ê°€ë§¹ì  ìƒ˜í”Œ:")
        for i, merchant in enumerate(list(matched_merchants)[:10]):
            print(f"   {i+1}. {merchant}")
        
        if len(matched_merchants) > 10:
            print(f"   ... ì™¸ {len(matched_merchants) - 10}ê°œ")
        
        # 6. ìë™ìœ¼ë¡œ ì—…ë°ì´íŠ¸ ì§„í–‰
        print(f"\nâœ… {len(matched_merchants)}ê°œ ê°€ë§¹ì ì˜ ì¹´í…Œê³ ë¦¬ë¥¼ 'ì²­ì£¼í˜ì´'ë¡œ ìë™ ë³€ê²½í•©ë‹ˆë‹¤...")
        
        # 7. ì¹´í…Œê³ ë¦¬ ì—…ë°ì´íŠ¸
        updated_count = updater.update_categories_to_cheongju_pay()
        
        # 8. ê²°ê³¼ ìë™ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"card_with_cheongju_pay.xlsx"
        
        print(f"ğŸ’¾ ê²°ê³¼ë¥¼ '{output_file}'ë¡œ ì €ì¥í•©ë‹ˆë‹¤...")
        saved_file = updater.save_updated_results(output_file)
        
        # 9. ìµœì¢… ê²°ê³¼ ìš”ì•½
        summary = updater.generate_summary_report()
        
        print(f"\nğŸ‰ ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"ğŸ“Š ê²°ê³¼ ìš”ì•½:")
        print(f"   - ì „ì²´ ê±°ë˜: {summary['total_transactions']:,}ê±´")
        print(f"   - ê³ ìœ  ê°€ë§¹ì : {summary['unique_merchants']:,}ê°œ")
        print(f"   - ë§¤ì¹­ëœ ê°€ë§¹ì : {summary['matched_merchants_count']}ê°œ")
        print(f"   - ì²­ì£¼í˜ì´ë¡œ ë³€ê²½: {summary['updated_transactions']:,}ê±´")
        print(f"   - ì²­ì£¼í˜ì´ ë¹„ìœ¨: {summary['cheongju_pay_ratio']}%")
        print(f"ğŸ’¾ ì €ì¥ëœ íŒŒì¼: {saved_file}")
        
    except Exception as e:
        print(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        logger.error(f"ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    main()

